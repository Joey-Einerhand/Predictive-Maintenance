{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fff731e7",
   "metadata": {},
   "source": [
    "# Predicitive maintanance model\n",
    "\n",
    "Made by: Joey Einerhand, CÃ©dric Cortenraede, Lennox Narinx, Giuseppe Collura"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76c4364",
   "metadata": {},
   "source": [
    "## Get file\n",
    "All files from the data directory will be loaded, _*this can take some time_\\\n",
    "based on the loaded data a dataframe will be created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bff32154",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Update \"data_dir\" location if necessary\n",
    "data_dir = \"data\"\n",
    "files = os.listdir(data_dir)\n",
    "files = [file for file in files if file != \"documentation.txt\" and file != 'description.txt' and file != 'profile.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d2a2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "# Load the sensor data\n",
    "# Takes the mean of each row to illuminate different frequencies\n",
    "for i in range(len(files)):\n",
    "    df[files[i].strip(\".txt\")] = pd.read_csv(os.path.join(data_dir, files[i]), sep=\"\\t\", header=None, names=[files[i]]).mean(axis=1).to_numpy()\n",
    "\n",
    "# Load the profiles\n",
    "profiles = [\"Cooler condition\", \"Valve condition\", \"Internal pump leakage\", \"Hydraulic accumulator\", \"Stable flag\"]\n",
    "for i in range(len(profiles)):\n",
    "    df[profiles[i]] = pd.read_csv(os.path.join(data_dir,'profile.txt'), sep=\"\\t\", header=None)[i].to_numpy()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d29c789",
   "metadata": {},
   "source": [
    "## Analyse data\n",
    "- The analysis looks at the correlation of the different columns in comparison to each other\\\n",
    "- This gives a filter to use later\\\n",
    "- The filter will be used to determine the columns impacting for the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e197047f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3936d441",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 25))\n",
    "\n",
    "i = 1\n",
    "for column in df:\n",
    "    data = df[column]\n",
    "    plt.subplot(math.ceil(len(df.columns) / 3), 3, i)\n",
    "    \n",
    "    plt.title(column)\n",
    "    plt.hist(data)\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057294f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 25))\n",
    "\n",
    "i = 1\n",
    "for column in df:\n",
    "    data = df[column]\n",
    "    plt.subplot(math.ceil(len(df.columns) / 3), 3, i)\n",
    "    \n",
    "    plt.title(column)\n",
    "    plt.boxplot(data)\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745480ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr()\n",
    "plt.figure(figsize=(30, 10))\n",
    "sb.heatmap(corr, cmap=\"Greens\", annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7a523c",
   "metadata": {},
   "source": [
    "## Making model\n",
    "## Predicting LSTM\n",
    "_Long Short Term Memory_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1807e48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM,Dropout,Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "plt.plot(df[\"Cooler condition\"], label=\"Cooler condition plot\")\n",
    "\n",
    "data = pd.DataFrame(index=range(0, len(df[\"Cooler condition\"])), columns=[\"Cooler condition\",\"TS1\", \"TS2\", \"TS3\", \"TS4\"])\n",
    "for i in range(0, len(data)):\n",
    "    data[\"Cooler condition\"][i] = df[\"Cooler condition\"][i]\n",
    "    data[\"TS1\"][i] = df[\"TS1\"][i]\n",
    "    data[\"TS2\"][i] = df[\"TS2\"][i]\n",
    "    data[\"TS3\"][i] = df[\"TS3\"][i]\n",
    "    data[\"TS4\"][i] = df[\"TS4\"][i]\n",
    "\n",
    "#data[\"Time\"] = data[\"Time\"].astype(int)\n",
    "data[\"Cooler condition\"] = data[\"Cooler condition\"].astype(int)\n",
    "data[\"TS1\"] = data[\"TS1\"].astype(float)\n",
    "data[\"TS2\"] = data[\"TS2\"].astype(float)\n",
    "data[\"TS3\"] = data[\"TS3\"].astype(float)\n",
    "data[\"TS4\"] = data[\"TS4\"].astype(float)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ad33a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler=MinMaxScaler(feature_range=(0,1))\n",
    "Y_scaler=MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "X_data = X_scaler.fit_transform(data[[\"TS1\", \"TS2\", \"TS3\", \"TS4\"]])\n",
    "Y_data = Y_scaler.fit_transform(data[[\"Cooler condition\"]])\n",
    "\n",
    "# split into train and test sets\n",
    "# Train is the dataset which the model is trained on\n",
    "# Test is the dataset which the model is verified with\n",
    "train_size = int(len(X_data) * 0.9)\n",
    "test_size = len(X_data) - train_size\n",
    "trainX, testX = X_data[0:train_size,:], X_data[train_size:len(X_data),:]\n",
    "trainY, testY = Y_data[0:train_size,:], Y_data[train_size:len(X_data),:]\n",
    "\n",
    "print(len(trainX), len(testX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b8c73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert an array of values into a dataset matrix\n",
    "# def create_dataset(dataset, look_back=1):\n",
    "# \tdataX, dataY = [], []\n",
    "# \tfor i in range(len(dataset)-look_back-1):\n",
    "# \t\ta = dataset[i:(i+look_back), 0]\n",
    "# \t\tdataX.append(a)\n",
    "# \t\tdataY.append(dataset[i + look_back, 0])\n",
    "# \treturn np.array(dataX), np.array(dataY)\n",
    "\n",
    "# # reshape into X=t and Y=t+1\n",
    "# look_back = 1\n",
    "# trainX, trainY = create_dataset(train, look_back)\n",
    "# testX, testY = create_dataset(test, look_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f4ee7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape into X=t and Y=t+1\n",
    "look_back = 1\n",
    "# trainX, trainY = create_dataset(train, look_back)\n",
    "# testX, testY = create_dataset(test, look_back)\n",
    "\n",
    "# reshape input to be [samples, time steps, features]\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322cdfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(look_back, 4)))\n",
    "#model.add(LSTM(4, return_sequences=True,stateful=True, batch_input_shape=(1, None,  look_back)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a294d10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # make predictions\n",
    "# import math\n",
    "# from sklearn.metrics import mean_squared_error \n",
    "\n",
    "# trainPredict = model.predict(trainX)\n",
    "# testPredict = model.predict(testX)\n",
    "# # invert predictions\n",
    "# trainPredict = X_scaler.inverse_transform(trainPredict)\n",
    "\n",
    "# #reshape\n",
    "# trainY.reshape((len(trainY), 1))\n",
    "\n",
    "\n",
    "# trainY = scaler.inverse_transform(trainY)\n",
    "# testPredict = scaler.inverse_transform(testPredict)\n",
    "\n",
    "\n",
    "# testY = scaler.inverse_transform(testY)\n",
    "# calculate root mean squared error\n",
    "# trainScore = math.sqrt(mean_squared_error(trainY, trainPredict[:,0]))\n",
    "# print('Train Score: %.2f RMSE' % (trainScore))\n",
    "# testScore = math.sqrt(mean_squared_error(testY, testPredict[:,0]))\n",
    "# print('Test Score: %.2f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265cc725",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try to predict a portion of the dataset with the trained model\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "\n",
    "# shift train predictions for plotting\n",
    "trainPredictPlot = np.empty_like(X_data)\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = np.empty_like(X_data)\n",
    "testPredictPlot[:, :] = np.nan\n",
    "#testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
    "testPredictPlot[len(trainPredict):len(X_data), :] = testPredict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384516b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------\n",
    "#  Convert data to something we can plot\n",
    "# ---------------------------------------\n",
    "\n",
    "\n",
    "# plot baseline and predictions\n",
    "# plt.plot(X_data, color=\"red\")\n",
    "# plt.plot(newTrainPredictPlot, color=\"blue\")\n",
    "# plt.plot(newTestPredictPlot, color=\"yellow\")\n",
    "plt.plot(Y_data, color=\"red\")\n",
    "plt.plot(trainPredictPlot, color=\"blue\")\n",
    "plt.plot(testPredictPlot, color=\"yellow\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ac87df",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ----------------------------\n",
    "## METRICS\n",
    "## ----------------------------\n",
    "def timeseries_evaluation_metrics_func(y_true, y_pred):\n",
    "    def mean_absolute_percentage_error(y_true, y_pred): \n",
    "        y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "        return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    print('Evaluation metric results:-')\n",
    "    print(f'MSE is : {metrics.mean_squared_error(y_true, y_pred)}')\n",
    "    print(f'MAE is : {metrics.mean_absolute_error(y_true, y_pred)}')\n",
    "    print(f'RMSE is : {np.sqrt(metrics.mean_squared_error(y_true, y_pred))}')\n",
    "    print(f'MAPE is : {mean_absolute_percentage_error(y_true, y_pred)}')\n",
    "    print(f'R2 is : {metrics.r2_score(y_true, y_pred)}',end='\\n\\n') \n",
    "    \n",
    "print(\"Training metrics\")\n",
    "timeseries_evaluation_metrics_func(trainY, trainPredict)\n",
    "print(\"Testing metrics\")\n",
    "timeseries_evaluation_metrics_func(testY, testPredict)\n",
    "\n",
    "# trainScore = math.sqrt(mean_squared_error(trainY, trainPredict[:,0]))\n",
    "# print('Train Score: %.2f RMSE' % (trainScore))\n",
    "# testScore = math.sqrt(mean_squared_error(testY, testPredict[:,0]))\n",
    "# print('Test Score: %.2f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cfe4af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a963f4a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58eb6a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
